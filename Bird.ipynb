{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import sqlparse\n",
    "from sqlparse.sql import TokenList\n",
    "from sqlparse.tokens import Whitespace, Keyword, Operator, Punctuation, Name, Literal\n",
    "\n",
    "# Load the JSON files\n",
    "with open('train.json') as f:\n",
    "\ttrain_data = json.load(f)\n",
    "\n",
    "with open('train_tables.json') as f:\n",
    "\ttrain_tables = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of SQL keywords\n",
    "keywords_main_body = {'SELECT', 'FROM', 'WHERE', 'AND', 'OR', 'NOT', 'IN', 'EXISTS', 'IS', 'NULL', 'IIF', 'CASE', 'WHEN'}\n",
    "keywords_join = {'INNER JOIN', 'LEFT JOIN', 'ON', 'AS'}\n",
    "keywords_clause = {'BETWEEN', 'LIKE', 'LIMIT', 'ORDER BY', 'ASC', 'DESC', 'GROUP BY', 'HAVING', 'UNION', 'ALL', 'EXCEPT', 'PARTITION BY', 'OVER'}\n",
    "keywords_aggregation = {'AVG', 'COUNT', 'MAX', 'MIN', 'ROUND', 'SUM'}\n",
    "keywords_scalar = {'ABS', 'LENGTH', 'STRFTIME', 'JULIADAY', 'NOW', 'CAST', 'SUBSTR', 'INSTR'}\n",
    "keywords_comparison = {'=', '>', '<', '>=', '<=', '!=', '<>'}\n",
    "keywords_computing = {'-', '+', '*', '/'}\n",
    "\n",
    "all_keywords = keywords_main_body | keywords_join | keywords_clause | keywords_aggregation | keywords_scalar | keywords_comparison | keywords_computing\n",
    "\n",
    "def get_id(entity_type):\n",
    "\tif entity_type == 'Alias':\n",
    "\t\treturn '<extra_id_0>'\n",
    "\telif entity_type == 'Table':\n",
    "\t\treturn '<extra_id_1>'\n",
    "\telif entity_type == 'Column':\n",
    "\t\treturn '<extra_id_2>'\n",
    "\telif entity_type == 'Value':\n",
    "\t\treturn '<extra_id_3>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlparse.lexer import Lexer\n",
    "from sqlparse import keywords\n",
    "\n",
    "# Get the lexer singleton object to configure it\n",
    "lex = Lexer.get_default_instance()\n",
    "\n",
    "# Clear the default configurations\n",
    "lex.clear()\n",
    "\n",
    "# Custom regex for DESC token\n",
    "desc_regex = (r\"\\bDESC\\b\", sqlparse.tokens.Keyword)\n",
    "alias_pattern = (r\"T\\d+\\..*\", sqlparse.tokens.Name)\n",
    "as_pattern = (r\"\\sAS\\s\", sqlparse.tokens.Keyword)\n",
    "# Inject the custom DESC token into the default SQL_REGEX\n",
    "lex.set_SQL_REGEX(keywords.SQL_REGEX[:38] + [desc_regex, as_pattern] + keywords.SQL_REGEX[38:])\n",
    "\n",
    "# Add the default keyword dictionaries\n",
    "lex.add_keywords(keywords.KEYWORDS_COMMON)\n",
    "lex.add_keywords(keywords.KEYWORDS_ORACLE)\n",
    "lex.add_keywords(keywords.KEYWORDS_PLPGSQL)\n",
    "lex.add_keywords(keywords.KEYWORDS_HQL)\n",
    "lex.add_keywords(keywords.KEYWORDS_MSACCESS)\n",
    "lex.add_keywords(keywords.KEYWORDS)\n",
    "\n",
    "# Add a custom keyword dictionary with DESC\n",
    "lex.add_keywords({\"DESC\": sqlparse.tokens.Keyword})\n",
    "\n",
    "# Test\n",
    "# sql_query = \"SELECT T3.age DESC FROM users T3 ORDER BY T3.age DESC\"\n",
    "# parsed = sqlparse.parse(sql_query)\n",
    "# for token in parsed[0].tokens:\n",
    "#     print(token, token.ttype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(sql_id,sql, verbose=False):\n",
    "    # Parse the SQL query and take the first statement\n",
    "    parsed = sqlparse.parse(sql)[0]\n",
    "    entities = []  # List to store identified entities\n",
    "    processed_tokens = []  # List to store processed tokens for reconstructed SQL\n",
    "\n",
    "    # Helper function to process each token in the parsed SQL\n",
    "    def process_token(token):\n",
    "        nonlocal processed_tokens\n",
    "        if verbose: print(f\"Processing token: '{token}' ({token.ttype})\")\n",
    "\n",
    "        # Processing based on token type\n",
    "        if isinstance(token, TokenList):\n",
    "            for sub_token in token.tokens:\n",
    "                process_token(sub_token)\n",
    "        elif token.ttype in (Whitespace, Keyword, Operator, Punctuation):\n",
    "            processed_tokens.append(token.value)\n",
    "        elif token.value.upper() in all_keywords:\n",
    "            if verbose: print(f\"        {token} is a keyword\")\n",
    "            processed_tokens.append(token.value)\n",
    "        elif token.ttype in (Name):\n",
    "            token_type = get_type(sql_id, token.value)\n",
    "            if token_type != 'None': append_entity(token.value, token_type)\n",
    "            if verbose: print(f\"        {token} is {token_type}\")\n",
    "            if token.ttype == Name.Builtin:\n",
    "                processed_tokens.append(token.value)\n",
    "        elif token.ttype in Literal:\n",
    "            if verbose: print(f\"        {token} is a Value\")\n",
    "            append_entity(token.value, \"Value\")\n",
    "\n",
    "    # Append entity to the list with its type and id\n",
    "    def append_entity(value, type):\n",
    "        entity_id = get_id(type)\n",
    "        entities.append((value, type, entity_id))\n",
    "        processed_tokens.append(entity_id)\n",
    "        if verbose: print(f\"        Appending entity: {value} as {type} with id {entity_id}\")\n",
    "\n",
    "    def get_type(sql_id, value):\n",
    "        alias_pattern = r\"T\\d+$\" # match \"T\" followed by any number of digits\n",
    "        if re.match(alias_pattern, value): return \"Alias\"\n",
    "        else:\n",
    "            for db in train_tables:\n",
    "                if db[\"db_id\"] == sql_id:\n",
    "                    if value in db[\"table_names_original\"]:\n",
    "                        return 'Table'\n",
    "                    elif value in [col[1] for col in db[\"column_names_original\"]]:\n",
    "                        return 'Column'\n",
    "                    else:\n",
    "                        return 'None'\n",
    "\n",
    "    # Process each token in the parsed tokens\n",
    "    for token in parsed.tokens:\n",
    "        process_token(token)\n",
    "        if verbose: print(\"-\" * 50)\n",
    "\n",
    "    # Combine tokens to reconstruct the processed SQL\n",
    "    processed_sql = ''.join(processed_tokens)\n",
    "    return entities, processed_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query 1: <SELECT CAST(COUNT(CASE WHEN T1.height_in_cm < 200 AND T2.nation = 'Russia' THEN T2.ELITEID ELSE NULL END) AS REAL) * 100 / COUNT(T2.ELITEID) FROM height_info AS T1 INNER JOIN PlayerInfo AS T2 ON T1.height_id = T2.height>\n",
      "\n",
      "ice_hockey_draft\n",
      "\n",
      "Processing token: 'SELECT' (Token.Keyword.DML)\n",
      "    SELECT is a keyword\n",
      "--------------------------------------------------\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "--------------------------------------------------\n",
      "Processing token: 'CAST(COUNT(CASE WHEN T1.height_in_cm < 200 AND T2.nation = 'Russia' THEN T2.ELITEID ELSE NULL END) AS REAL) * 100 / COUNT(T2.ELITEID)' (None)\n",
      "Processing token: 'CAST(COUNT(CASE WHEN T1.height_in_cm < 200 AND T2.nation = 'Russia' THEN T2.ELITEID ELSE NULL END) AS REAL) * 100' (None)\n",
      "Processing token: 'CAST(COUNT(CASE WHEN T1.height_in_cm < 200 AND T2.nation = 'Russia' THEN T2.ELITEID ELSE NULL END) AS REAL)' (None)\n",
      "Processing token: 'CAST' (None)\n",
      "Processing token: 'CAST' (Token.Name)\n",
      "    CAST is a keyword\n",
      "Processing token: '(COUNT(CASE WHEN T1.height_in_cm < 200 AND T2.nation = 'Russia' THEN T2.ELITEID ELSE NULL END) AS REAL)' (None)\n",
      "Processing token: '(' (Token.Punctuation)\n",
      "Processing token: 'COUNT(CASE WHEN T1.height_in_cm < 200 AND T2.nation = 'Russia' THEN T2.ELITEID ELSE NULL END) AS REAL' (None)\n",
      "Processing token: 'COUNT(CASE WHEN T1.height_in_cm < 200 AND T2.nation = 'Russia' THEN T2.ELITEID ELSE NULL END)' (None)\n",
      "Processing token: 'COUNT' (None)\n",
      "Processing token: 'COUNT' (Token.Name)\n",
      "    COUNT is a keyword\n",
      "Processing token: '(CASE WHEN T1.height_in_cm < 200 AND T2.nation = 'Russia' THEN T2.ELITEID ELSE NULL END)' (None)\n",
      "Processing token: '(' (Token.Punctuation)\n",
      "Processing token: 'CASE WHEN T1.height_in_cm < 200 AND T2.nation = 'Russia' THEN T2.ELITEID ELSE NULL END' (None)\n",
      "Processing token: 'CASE' (Token.Keyword)\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'WHEN' (Token.Keyword)\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'T1.height_in_cm < 200' (None)\n",
      "Processing token: 'T1.height_in_cm' (None)\n",
      "Processing token: 'T1' (Token.Name)\n",
      "        Appending entity: T1 as Alias with id <extra_id_0>\n",
      "    T1 is Alias\n",
      "Processing token: '.' (Token.Punctuation)\n",
      "Processing token: 'height_in_cm' (Token.Name)\n",
      "        Appending entity: height_in_cm as Column with id <extra_id_2>\n",
      "    height_in_cm is Column\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: '<' (Token.Operator.Comparison)\n",
      "    < is a keyword\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: '200' (Token.Literal.Number.Integer)\n",
      "    200 is a Value\n",
      "        Appending entity: 200 as Value with id <extra_id_3>\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'AND' (Token.Keyword)\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'T2.nation = 'Russia'' (None)\n",
      "Processing token: 'T2.nation' (None)\n",
      "Processing token: 'T2' (Token.Name)\n",
      "        Appending entity: T2 as Alias with id <extra_id_0>\n",
      "    T2 is Alias\n",
      "Processing token: '.' (Token.Punctuation)\n",
      "Processing token: 'nation' (Token.Name)\n",
      "        Appending entity: nation as Column with id <extra_id_2>\n",
      "    nation is Column\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: '=' (Token.Operator.Comparison)\n",
      "    = is a keyword\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: ''Russia'' (Token.Literal.String.Single)\n",
      "    'Russia' is a Value\n",
      "        Appending entity: 'Russia' as Value with id <extra_id_3>\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'THEN' (Token.Keyword)\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'T2.ELITEID' (None)\n",
      "Processing token: 'T2' (Token.Name)\n",
      "        Appending entity: T2 as Alias with id <extra_id_0>\n",
      "    T2 is Alias\n",
      "Processing token: '.' (Token.Punctuation)\n",
      "Processing token: 'ELITEID' (Token.Name)\n",
      "        Appending entity: ELITEID as Column with id <extra_id_2>\n",
      "    ELITEID is Column\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'ELSE' (Token.Keyword)\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'NULL' (Token.Keyword)\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'END' (Token.Keyword)\n",
      "Processing token: ')' (Token.Punctuation)\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'AS' (Token.Keyword)\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'REAL' (Token.Name.Builtin)\n",
      "    REAL is None\n",
      "Processing token: ')' (Token.Punctuation)\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: '*' (Token.Operator)\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: '100' (Token.Literal.Number.Integer)\n",
      "    100 is a Value\n",
      "        Appending entity: 100 as Value with id <extra_id_3>\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: '/' (Token.Operator)\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'COUNT(T2.ELITEID)' (None)\n",
      "Processing token: 'COUNT' (None)\n",
      "Processing token: 'COUNT' (Token.Name)\n",
      "    COUNT is a keyword\n",
      "Processing token: '(T2.ELITEID)' (None)\n",
      "Processing token: '(' (Token.Punctuation)\n",
      "Processing token: 'T2.ELITEID' (None)\n",
      "Processing token: 'T2' (Token.Name)\n",
      "        Appending entity: T2 as Alias with id <extra_id_0>\n",
      "    T2 is Alias\n",
      "Processing token: '.' (Token.Punctuation)\n",
      "Processing token: 'ELITEID' (Token.Name)\n",
      "        Appending entity: ELITEID as Column with id <extra_id_2>\n",
      "    ELITEID is Column\n",
      "Processing token: ')' (Token.Punctuation)\n",
      "--------------------------------------------------\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "--------------------------------------------------\n",
      "Processing token: 'FROM' (Token.Keyword)\n",
      "--------------------------------------------------\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "--------------------------------------------------\n",
      "Processing token: 'height_info AS T1' (None)\n",
      "Processing token: 'height_info' (Token.Name)\n",
      "        Appending entity: height_info as Table with id <extra_id_1>\n",
      "    height_info is Table\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'AS' (Token.Keyword)\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'T1' (None)\n",
      "Processing token: 'T1' (Token.Name)\n",
      "        Appending entity: T1 as Alias with id <extra_id_0>\n",
      "    T1 is Alias\n",
      "--------------------------------------------------\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "--------------------------------------------------\n",
      "Processing token: 'INNER JOIN' (Token.Keyword)\n",
      "--------------------------------------------------\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "--------------------------------------------------\n",
      "Processing token: 'PlayerInfo AS T2' (None)\n",
      "Processing token: 'PlayerInfo' (Token.Name)\n",
      "        Appending entity: PlayerInfo as Table with id <extra_id_1>\n",
      "    PlayerInfo is Table\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'AS' (Token.Keyword)\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'T2' (None)\n",
      "Processing token: 'T2' (Token.Name)\n",
      "        Appending entity: T2 as Alias with id <extra_id_0>\n",
      "    T2 is Alias\n",
      "--------------------------------------------------\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "--------------------------------------------------\n",
      "Processing token: 'ON' (Token.Keyword)\n",
      "--------------------------------------------------\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "--------------------------------------------------\n",
      "Processing token: 'T1.height_id = T2.height' (None)\n",
      "Processing token: 'T1.height_id' (None)\n",
      "Processing token: 'T1' (Token.Name)\n",
      "        Appending entity: T1 as Alias with id <extra_id_0>\n",
      "    T1 is Alias\n",
      "Processing token: '.' (Token.Punctuation)\n",
      "Processing token: 'height_id' (Token.Name)\n",
      "        Appending entity: height_id as Column with id <extra_id_2>\n",
      "    height_id is Column\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: '=' (Token.Operator.Comparison)\n",
      "    = is a keyword\n",
      "Processing token: ' ' (Token.Text.Whitespace)\n",
      "Processing token: 'T2.height' (None)\n",
      "Processing token: 'T2' (Token.Name)\n",
      "        Appending entity: T2 as Alias with id <extra_id_0>\n",
      "    T2 is Alias\n",
      "Processing token: '.' (Token.Punctuation)\n",
      "Processing token: 'height' (Token.Name)\n",
      "        Appending entity: height as Column with id <extra_id_2>\n",
      "    height is Column\n",
      "--------------------------------------------------\n",
      "Entity                         Type            ID                  \n",
      "T1                             Alias           <extra_id_0>        \n",
      "T2                             Alias           <extra_id_0>        \n",
      "height_info                    Table           <extra_id_1>        \n",
      "PlayerInfo                     Table           <extra_id_1>        \n",
      "height_in_cm                   Column          <extra_id_2>        \n",
      "nation                         Column          <extra_id_2>        \n",
      "ELITEID                        Column          <extra_id_2>        \n",
      "height_id                      Column          <extra_id_2>        \n",
      "height                         Column          <extra_id_2>        \n",
      "200                            Value           <extra_id_3>        \n",
      "'Russia'                       Value           <extra_id_3>        \n",
      "100                            Value           <extra_id_3>        \n",
      "\n",
      "Initial SQL: SELECT CAST(COUNT(CASE WHEN T1.height_in_cm < 200 AND T2.nation = 'Russia' THEN T2.ELITEID ELSE NULL END) AS REAL) * 100 / COUNT(T2.ELITEID) FROM height_info AS T1 INNER JOIN PlayerInfo AS T2 ON T1.height_id = T2.height\n",
      "Masked SQL: SELECT CAST(COUNT(CASE WHEN <extra_id_0>.<extra_id_2> < <extra_id_3> AND <extra_id_0>.<extra_id_2> = <extra_id_3> THEN <extra_id_0>.<extra_id_2> ELSE NULL END) AS REAL) * <extra_id_3> / COUNT(<extra_id_0>.<extra_id_2>) FROM <extra_id_1> AS <extra_id_0> INNER JOIN <extra_id_1> AS <extra_id_0> ON <extra_id_0>.<extra_id_2> = <extra_id_0>.<extra_id_2>\n",
      "==================================================\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "sample = [train_data[i] for i in [6969]]\n",
    "\n",
    "# Extract entity and print results\n",
    "for i, data in enumerate(sample):\n",
    "\tsql_query = data[\"SQL\"]\n",
    "\tsql_id = data[\"db_id\"]\n",
    "\tprint(f\"Query {i+1}: <{sql_query}>\\n\")\n",
    "\tprint(sql_id+\"\\n\")\n",
    "\tentities, processed_sql = extract_entities(sql_id,sql_query,verbose=True)\n",
    "\n",
    "\t# Entity Table\n",
    "\theaders = [\"Entity\", \"Type\", \"ID\"]\n",
    "\tprint(f\"{headers[0]:<30} {headers[1]:<15} {headers[2]:<20}\")\n",
    "\t\n",
    "\t# Filter out duplicates\n",
    "\tseen = set()\n",
    "\tunique_entities = []\n",
    "\tfor entity in entities:\n",
    "\t\tif entity not in seen:\n",
    "\t\t\tseen.add(entity)\n",
    "\t\t\tunique_entities.append(entity)\n",
    "\t\n",
    "\t# Sort and print unique entities\n",
    "\tunique_entities = sorted(unique_entities, key=lambda x: x[2])\n",
    "\tfor entity in unique_entities:\n",
    "\t\tprint(f\"{entity[0]:<30} {entity[1]:<15} {entity[2]:<20}\")\n",
    "\t# Masked SQL\n",
    "\tprint(\"\\nInitial SQL:\",sql_query)\n",
    "\tprint(\"Masked SQL:\",processed_sql)\n",
    "\tprint(\"=\" * 50)\n",
    "\tprint(\"=\" * 50)\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT director_name FROM movies WHERE movie_title = 'Sex, Drink and Bloodshed'\n",
      "SELECT\n",
      "TARGET Token.Literal.String.Single\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "with open('train.json') as f:\n",
    "\ttrain_data = json.load(f)\n",
    "\t\n",
    "sql=train_data[15][\"SQL\"]\n",
    "print(sql)\n",
    "parsed = sqlparse.parse(sql)[0]\n",
    "print(parsed.token_first())\n",
    "\n",
    "a1=parsed.tokens[8].tokens[2].tokens[4].ttype\n",
    "a2=sqlparse.tokens.String\n",
    "print(\"TARGET\",parsed.tokens[8].tokens[2].tokens[4].ttype)\n",
    "print(a1 in a2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
